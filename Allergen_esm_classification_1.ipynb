{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdqzpG_U78GR",
        "outputId": "74ceafb0-d36b-42d5-c0f3-18cb3a513c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: fair-esm in /home/molecular16/.local/lib/python3.11/site-packages (2.0.0)\n",
            "Requirement already satisfied: torch in /home/molecular16/.local/lib/python3.11/site-packages (2.7.1)\n",
            "Requirement already satisfied: filelock in /home/molecular16/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/molecular16/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /home/molecular16/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /home/molecular16/.local/lib/python3.11/site-packages (from torch) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from triton==3.3.1->torch) (68.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install fair-esm torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ng1VNIh8GP5",
        "outputId": "94be2a41-dabc-4e42-fd97-dd4ee6b6e6da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zXiWoP07zCl"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    matthews_corrcoef, cohen_kappa_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import esm\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
        "\n",
        "# Load ESM model\n",
        "esm_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "esm_model.eval()\n",
        "\n",
        "# Dataset Class with data augmentation\n",
        "class PeptideDataset(Dataset):\n",
        "    def __init__(self, csv_file, augment=False):\n",
        "        df = pd.read_csv(csv_file)\n",
        "        self.sequences = df['sequence'].astype(str).tolist()\n",
        "        self.labels = df['Allergen'].tolist()\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Simple data augmentation - reverse sequence\n",
        "        if self.augment and torch.rand(1).item() > 0.5:\n",
        "            seq = seq[::-1]\n",
        "\n",
        "        return seq, label\n",
        "\n",
        "# ESM Embedding Extractor with caching\n",
        "@torch.no_grad()\n",
        "def extract_esm_embeddings(sequences):\n",
        "    sequences_upper = [seq.upper() for seq in sequences]\n",
        "    data = [(\"seq\", seq) for seq in sequences_upper]\n",
        "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
        "    results = esm_model(batch_tokens, repr_layers=[6], return_contacts=False)\n",
        "    token_representations = results[\"representations\"][6]\n",
        "\n",
        "    embeddings = []\n",
        "    for i, seq in enumerate(sequences_upper):\n",
        "        emb = token_representations[i, 1:len(seq)+1].mean(0)\n",
        "        embeddings.append(emb)\n",
        "    return torch.stack(embeddings)\n",
        "\n",
        "# Improved TCN Blocks\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super().__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                              stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.bn1 = nn.BatchNorm1d(n_outputs)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                              stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.bn2 = nn.BatchNorm1d(n_outputs)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            self.conv1, self.chomp1, self.bn1, nn.GELU(), self.dropout1,\n",
        "            self.conv2, self.chomp2, self.bn2, nn.GELU(), self.dropout2\n",
        "        )\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_in')  # removed nonlinearity\n",
        "        nn.init.kaiming_normal_(self.conv2.weight, mode='fan_in')  # removed nonlinearity\n",
        "        if self.downsample is not None:\n",
        "            nn.init.kaiming_normal_(self.downsample.weight, mode='fan_in')  # removed nonlinearity\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return F.gelu(out + res)\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, num_channels, kernel_size=3, dropout=0.2):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for i in range(len(num_channels)):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = input_size if i == 0 else num_channels[i - 1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers.append(\n",
        "                TemporalBlock(in_channels, out_channels, kernel_size, stride=1,\n",
        "                            dilation=dilation_size, padding=(kernel_size - 1) * dilation_size,\n",
        "                            dropout=dropout)\n",
        "            )\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Improved Adaptive Feature Fusion\n",
        "class AdaptiveFusion(nn.Module):\n",
        "    def __init__(self, esm_dim, tcn_dim):\n",
        "        super().__init__()\n",
        "        self.fc_esm = nn.Sequential(\n",
        "            nn.Linear(esm_dim, esm_dim),\n",
        "            nn.LayerNorm(esm_dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "        self.fc_tcn = nn.Sequential(\n",
        "            nn.Linear(tcn_dim, esm_dim),\n",
        "            nn.LayerNorm(esm_dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(esm_dim * 2, esm_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, esm_feat, tcn_feat):\n",
        "        esm_proj = self.fc_esm(esm_feat)\n",
        "        tcn_proj = self.fc_tcn(tcn_feat)\n",
        "\n",
        "        combined = torch.cat([esm_proj, tcn_proj], dim=1)\n",
        "        gate = self.gate(combined)\n",
        "\n",
        "        return gate * esm_proj + (1 - gate) * tcn_proj\n",
        "\n",
        "# Label Smoothing Cross Entropy\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        log_probs = F.log_softmax(x, dim=-1)\n",
        "        nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -log_probs.mean(dim=-1)\n",
        "        loss = (1.0 - self.smoothing) * nll_loss + self.smoothing * smooth_loss\n",
        "        return loss.mean()\n",
        "\n",
        "# Improved LSTM with LayerNorm and dropout\n",
        "class LayerNormLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
        "\n",
        "        # Layer normalization\n",
        "        self.ln_i = nn.LayerNorm(hidden_size)\n",
        "        self.ln_h = nn.LayerNorm(hidden_size)\n",
        "        self.ln_c = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward propagate LSTM\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "\n",
        "        # Apply layer normalization\n",
        "        hn = self.ln_h(hn)\n",
        "        cn = self.ln_c(cn)\n",
        "\n",
        "        return out, (hn, cn)\n",
        "\n",
        "# Complete Classifier Model with improvements\n",
        "class MultimodalClassifier(nn.Module):\n",
        "    def __init__(self, esm_dim=320, tcn_input=21, tcn_channels=[64, 128], lstm_hidden=128, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # TCN pathway\n",
        "        self.tcn = TCN(tcn_input, tcn_channels)\n",
        "\n",
        "        # Feature fusion\n",
        "        self.fusion = AdaptiveFusion(esm_dim, tcn_channels[-1])\n",
        "\n",
        "        # LSTM pathway with layer normalization\n",
        "        self.lstm = LayerNormLSTM(input_size=esm_dim, hidden_size=lstm_hidden,\n",
        "                                num_layers=3, dropout=0.3)\n",
        "\n",
        "        # Classifier head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_hidden, lstm_hidden // 2),\n",
        "            nn.LayerNorm(lstm_hidden // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(lstm_hidden // 2, num_classes)\n",
        "        )\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                if param.dim() < 2:  # Skip initialization for 1D tensors\n",
        "                    continue\n",
        "                if 'lstm' in name.lower():\n",
        "                    nn.init.orthogonal_(param)\n",
        "                else:\n",
        "                    nn.init.kaiming_normal_(param, mode='fan_in')\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0)\n",
        "\n",
        "    def forward(self, esm_feats, onehot_seqs):\n",
        "        # TCN pathway\n",
        "        tcn_out = self.tcn(onehot_seqs.permute(0, 2, 1))\n",
        "        tcn_summary = torch.mean(tcn_out, dim=2)  # Global pooling\n",
        "\n",
        "        # Feature fusion\n",
        "        fused = self.fusion(esm_feats, tcn_summary)\n",
        "\n",
        "        # Prepare LSTM input (repeat fused features to simulate sequence)\n",
        "        lstm_input = fused.unsqueeze(1).repeat(1, 10, 1)\n",
        "\n",
        "        # LSTM pathway\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "\n",
        "        # Classifier\n",
        "        out = self.classifier(lstm_out[:, -1])\n",
        "        return out\n",
        "\n",
        "# Improved training function with gradient clipping, warmup, and more\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50,\n",
        "               patience=5, grad_clip=1.0, grad_accum_steps=4):\n",
        "    history = {\"train_loss\": [], \"val_loss\": []}\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    # Learning rate schedulers\n",
        "    warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer, lambda epoch: min(1.0, (epoch + 1) / 10))\n",
        "    reduce_lr = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for i, (sequences, labels) in enumerate(tqdm(train_loader)):\n",
        "            esm_feats = extract_esm_embeddings(sequences)\n",
        "            onehot_seqs = sequence_to_onehot(sequences).float()\n",
        "            labels = torch.tensor(labels).long()\n",
        "\n",
        "            outputs = model(esm_feats, onehot_seqs)\n",
        "            loss = criterion(outputs, labels) / grad_accum_steps\n",
        "            loss.backward()\n",
        "\n",
        "            train_loss += loss.item() * grad_accum_steps\n",
        "\n",
        "            # Gradient accumulation\n",
        "            if (i + 1) % grad_accum_steps == 0 or (i + 1) == len(train_loader):\n",
        "                # Gradient clipping\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for sequences, labels in val_loader:\n",
        "                esm_feats = extract_esm_embeddings(sequences)\n",
        "                onehot_seqs = sequence_to_onehot(sequences).float()\n",
        "                labels = torch.tensor(labels).long()\n",
        "\n",
        "                outputs = model(esm_feats, onehot_seqs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        if epoch < 10:  # Warmup phase\n",
        "            warmup_scheduler.step()\n",
        "        else:\n",
        "            reduce_lr.step(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                print(f'Early stopping at epoch {epoch+1}')\n",
        "                model.load_state_dict(torch.load('best_model.pt'))\n",
        "                break\n",
        "\n",
        "    return history\n",
        "\n",
        "# Utility Functions\n",
        "def sequence_to_onehot(sequences, max_len=100):\n",
        "    amino_acids = 'RHKDESTNQCUGPAVILMFYW'\n",
        "    aa_to_idx = {aa: i for i, aa in enumerate(amino_acids)}\n",
        "    onehot = torch.zeros(len(sequences), max_len, len(amino_acids))\n",
        "    for i, seq in enumerate(sequences):\n",
        "        seq_upper = seq.upper()\n",
        "        for j, aa in enumerate(seq_upper[:max_len]):\n",
        "            if aa in aa_to_idx:\n",
        "                onehot[i, j, aa_to_idx[aa]] = 1.0\n",
        "    return onehot\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in data_loader:\n",
        "            esm_feats = extract_esm_embeddings(sequences)\n",
        "            onehot_seqs = sequence_to_onehot(sequences).float()\n",
        "            outputs = model(esm_feats, onehot_seqs)\n",
        "            preds = torch.argmax(outputs, dim=1).numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(all_labels, all_preds),\n",
        "        \"Precision\": precision_score(all_labels, all_preds),\n",
        "        \"Recall\": recall_score(all_labels, all_preds),\n",
        "        \"F1-score\": f1_score(all_labels, all_preds),\n",
        "        \"MCC\": matthews_corrcoef(all_labels, all_preds),\n",
        "        \"Cohen's Kappa\": cohen_kappa_score(all_labels, all_preds)\n",
        "    }\n",
        "\n",
        "    for name, value in metrics.items():\n",
        "        print(f\"{name}: {value:.4f}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Training/Validation Loss\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRWmKSOJ75z6",
        "outputId": "f976d1d3-5a1a-4060-facc-a34591703502"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                  | 0/2000 [00:00<?, ?it/s]/home/molecular16/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/tmp/ipykernel_845172/783620447.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels).long()\n",
            "100%|███████████████████████████████████████| 2000/2000 [01:18<00:00, 25.57it/s]\n",
            "/tmp/ipykernel_845172/783620447.py:292: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels).long()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 0.3315, Val Loss: 0.2807, LR: 2.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:16<00:00, 26.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Train Loss: 0.2651, Val Loss: 0.2622, LR: 3.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:18<00:00, 25.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Train Loss: 0.2511, Val Loss: 0.2485, LR: 4.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:19<00:00, 25.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Train Loss: 0.2428, Val Loss: 0.2516, LR: 5.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:16<00:00, 26.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Train Loss: 0.2340, Val Loss: 0.2313, LR: 6.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:18<00:00, 25.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Train Loss: 0.2283, Val Loss: 0.2229, LR: 7.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Train Loss: 0.2244, Val Loss: 0.2164, LR: 8.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:15<00:00, 26.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Train Loss: 0.2209, Val Loss: 0.2134, LR: 9.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Train Loss: 0.2160, Val Loss: 0.2091, LR: 1.00e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Train Loss: 0.2156, Val Loss: 0.2118, LR: 1.00e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:16<00:00, 26.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Train Loss: 0.2136, Val Loss: 0.2158, LR: 1.00e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Train Loss: 0.2118, Val Loss: 0.2079, LR: 1.00e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Train Loss: 0.2108, Val Loss: 0.2165, LR: 1.00e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Train Loss: 0.2100, Val Loss: 0.2195, LR: 1.00e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:14<00:00, 26.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Train Loss: 0.2071, Val Loss: 0.2143, LR: 5.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:14<00:00, 26.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Train Loss: 0.2066, Val Loss: 0.2126, LR: 5.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:10<00:00, 28.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Train Loss: 0.2054, Val Loss: 0.2059, LR: 5.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:14<00:00, 26.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Train Loss: 0.2051, Val Loss: 0.2047, LR: 5.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Train Loss: 0.2042, Val Loss: 0.2026, LR: 5.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:16<00:00, 26.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Train Loss: 0.2046, Val Loss: 0.2038, LR: 5.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21, Train Loss: 0.2033, Val Loss: 0.2058, LR: 5.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:18<00:00, 25.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22, Train Loss: 0.2035, Val Loss: 0.2038, LR: 2.50e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23, Train Loss: 0.2021, Val Loss: 0.2030, LR: 2.50e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:18<00:00, 25.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24, Train Loss: 0.2028, Val Loss: 0.2055, LR: 2.50e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:15<00:00, 26.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25, Train Loss: 0.2024, Val Loss: 0.2059, LR: 1.25e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:19<00:00, 25.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26, Train Loss: 0.2022, Val Loss: 0.2016, LR: 1.25e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:16<00:00, 25.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27, Train Loss: 0.2023, Val Loss: 0.2075, LR: 1.25e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:16<00:00, 26.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28, Train Loss: 0.2025, Val Loss: 0.2032, LR: 1.25e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29, Train Loss: 0.2017, Val Loss: 0.2065, LR: 6.25e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:14<00:00, 26.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30, Train Loss: 0.2015, Val Loss: 0.2034, LR: 6.25e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:16<00:00, 26.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31, Train Loss: 0.2015, Val Loss: 0.2034, LR: 6.25e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:14<00:00, 26.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32, Train Loss: 0.2015, Val Loss: 0.2026, LR: 3.13e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:16<00:00, 26.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33, Train Loss: 0.2012, Val Loss: 0.2033, LR: 3.13e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:19<00:00, 25.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34, Train Loss: 0.2016, Val Loss: 0.2036, LR: 3.13e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:15<00:00, 26.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35, Train Loss: 0.2015, Val Loss: 0.2033, LR: 1.56e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36, Train Loss: 0.2015, Val Loss: 0.2027, LR: 1.56e-06\n",
            "Early stopping at epoch 36\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Set Evaluation:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 0.9999\n",
            "F1-score: 1.0000\n",
            "MCC: 0.9999\n",
            "Cohen's Kappa: 0.9999\n",
            "\n",
            "Validation Set Evaluation:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/molecular16/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9984\n",
            "Precision: 0.9997\n",
            "Recall: 0.9970\n",
            "F1-score: 0.9984\n",
            "MCC: 0.9968\n",
            "Cohen's Kappa: 0.9968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/molecular16/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/molecular16/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize with data augmentation for training\n",
        "    full_dataset = PeptideDataset(\"Allergen_combined.csv\", augment=True)\n",
        "\n",
        "    # Stratified split\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    indices = list(range(len(full_dataset)))\n",
        "    labels = [full_dataset[i][1] for i in indices]\n",
        "    train_idx, val_idx = train_test_split(indices, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "    train_dataset = torch.utils.data.Subset(full_dataset, train_idx)\n",
        "    val_dataset = torch.utils.data.Subset(\n",
        "        PeptideDataset(\"Allergen_combined.csv\", augment=False),\n",
        "        val_idx\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, num_workers=4, pin_memory=True)\n",
        "\n",
        "    model = MultimodalClassifier()\n",
        "\n",
        "    # Use label smoothing and gradient clipping\n",
        "    criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "    history = train_model(\n",
        "        model, train_loader, val_loader, criterion, optimizer,\n",
        "        num_epochs=100, patience=10, grad_clip=1.0, grad_accum_steps=2\n",
        "    )\n",
        "\n",
        "    plot_history(history)\n",
        "\n",
        "    print(\"\\nTrain Set Evaluation:\")\n",
        "    train_metrics = evaluate_model(model, train_loader)\n",
        "\n",
        "    print(\"\\nValidation Set Evaluation:\")\n",
        "    val_metrics = evaluate_model(model, val_loader)\n",
        "\n",
        "    # Confusion matrix plotting\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import seaborn as sns\n",
        "\n",
        "    def plot_confusion_matrix(model, data_loader, title):\n",
        "        all_preds, all_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for sequences, labels in data_loader:\n",
        "                esm_feats = extract_esm_embeddings(sequences)\n",
        "                onehot_seqs = sequence_to_onehot(sequences).float()\n",
        "                outputs = model(esm_feats, onehot_seqs)\n",
        "                preds = torch.argmax(outputs, dim=1).numpy()\n",
        "                all_preds.extend(preds)\n",
        "                all_labels.extend(labels)\n",
        "\n",
        "        cm = confusion_matrix(all_labels, all_preds)\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "        plt.xlabel(\"Predicted Label\")\n",
        "        plt.ylabel(\"True Label\")\n",
        "        plt.title(title)\n",
        "        plt.show()\n",
        "\n",
        "    plot_confusion_matrix(model, train_loader, \"Confusion Matrix - Training Set\")\n",
        "    plot_confusion_matrix(model, val_loader, \"Confusion Matrix - Validation Set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEbC7txn72IX",
        "outputId": "4131d4c3-139b-4867-dec6-c246759dd31b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/molecular16/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/molecular16/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(model, data_loader, title):\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in data_loader:\n",
        "            esm_feats = extract_esm_embeddings(sequences)\n",
        "            onehot_seqs = sequence_to_onehot(sequences).float()\n",
        "            outputs = model(esm_feats, onehot_seqs)\n",
        "            preds = torch.argmax(outputs, dim=1).numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(model, train_loader, \"Confusion Matrix - Training Set\")\n",
        "plot_confusion_matrix(model, val_loader, \"Confusion Matrix - Validation Set\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEZ4znu4UA9F",
        "outputId": "32d908de-7a47-4a0d-94a3-6ce9856649b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allergen\n",
            "1.0    20000\n",
            "0.0    20000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as df\n",
        "df = pd.read_csv(\"Allergen_combined.csv\")\n",
        "toxin_counts = df['Allergen'].value_counts()\n",
        "print(toxin_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSVxhlTLUX6Z"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'Allergen_peptide_classifier.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecrXE-pXUX1Y",
        "outputId": "0136dfe3-26b7-46e9-ee16-299b7e6154d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n",
            "Predictions: tensor([0, 0])\n"
          ]
        }
      ],
      "source": [
        "# To open the trained model, you would load the state dictionary back into a model instance\n",
        "# First, instantiate a new model with the same architecture\n",
        "model = MultimodalClassifier()\n",
        "\n",
        "# Then, load the saved state dictionary\n",
        "model.load_state_dict(torch.load('Allergen_peptide_classifier.pth'))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# You can now use loaded_model for inference on new data.\n",
        "# Example (assuming you have new_sequences):\n",
        "new_sequences = [\"ARGLAKL\", \"AAVVRR\"]\n",
        "new_esm_feats = extract_esm_embeddings(new_sequences)\n",
        "new_onehot_seqs = sequence_to_onehot(new_sequences).float()\n",
        "with torch.no_grad():\n",
        "     predictions = model(new_esm_feats, new_onehot_seqs)\n",
        "     predicted_classes = torch.argmax(predictions, dim=1)\n",
        "     print(\"Predictions:\", predicted_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgUjvORpUX0b",
        "outputId": "defa326e-f548-4f4f-b9a1-da39f38aacd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: lime in /home/molecular16/.local/lib/python3.11/site-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /home/molecular16/anaconda3/lib/python3.11/site-packages (from lime) (3.7.2)\n",
            "Requirement already satisfied: numpy in /home/molecular16/anaconda3/lib/python3.11/site-packages (from lime) (1.24.3)\n",
            "Requirement already satisfied: scipy in /home/molecular16/anaconda3/lib/python3.11/site-packages (from lime) (1.11.1)\n",
            "Requirement already satisfied: tqdm in /home/molecular16/anaconda3/lib/python3.11/site-packages (from lime) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from lime) (1.3.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from lime) (0.20.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (3.1)\n",
            "Requirement already satisfied: pillow>=9.0.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (2.31.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (23.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime) (0.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.18->lime) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.18->lime) (2.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime) (1.4.4)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-iobrzmaUXwZ",
        "outputId": "a6629d99-088d-4d82-d5f4-09ef16d8e271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lime'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1520876531.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlime_text\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLimeTextExplainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lime'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# === Load dataset ===\n",
        "df = pd.read_csv(\"Allergen_combined.csv\")\n",
        "df['sequence'] = df['sequence'].astype(str)\n",
        "df['label'] = df['Allergen']\n",
        "\n",
        "# Drop sequences with length smaller than 6 and create a new dataframe\n",
        "df = df[df['sequence'].str.len() >= 8].copy()\n",
        "\n",
        "# === Tokenization into k-mers ===\n",
        "def seq_to_kmers(seq, k=6):\n",
        "    return ' '.join([seq[i:i + k] for i in range(len(seq) - k + 1)])\n",
        "\n",
        "k = 8\n",
        "df['kmers'] = df['sequence'].apply(lambda seq: seq_to_kmers(seq, k))\n",
        "\n",
        "# === Helper to reconstruct full sequence from k-mers ===\n",
        "def kmers_to_seq(kmer_str, k=8):\n",
        "    kmers = kmer_str.split()\n",
        "    if not kmers:\n",
        "        return ''\n",
        "    return kmers[0] + ''.join([k[-1] for k in kmers[1:]])\n",
        "\n",
        "# === Prediction wrapper for LIME (accepts k-mer strings) ===\n",
        "class_names = ['non-Allergen', 'Allergen']\n",
        "\n",
        "def lime_predict_kmers(kmer_texts):\n",
        "    # Convert k-mer text back to raw sequences\n",
        "    sequences = [kmers_to_seq(text, k) for text in kmer_texts]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Filter out invalid inputs\n",
        "        valid_sequences = [seq for seq in sequences if isinstance(seq, str) and len(seq) > 0]\n",
        "        if not valid_sequences:\n",
        "            return np.array([[0.5, 0.5]] * len(sequences))\n",
        "\n",
        "        # ESM and one-hot encodings\n",
        "        esm_feats = extract_esm_embeddings(valid_sequences)  # tensor [B, D]\n",
        "        onehot_seqs = sequence_to_onehot(valid_sequences).float()  # tensor [B, L, 4]\n",
        "        outputs = model(esm_feats, onehot_seqs)\n",
        "        probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
        "\n",
        "        # Reassign to full array\n",
        "        full_probs = np.zeros((len(sequences), len(class_names)))\n",
        "        valid_idx = 0\n",
        "        for i, seq in enumerate(sequences):\n",
        "            if isinstance(seq, str) and len(seq) > 0:\n",
        "                full_probs[i] = probs[valid_idx]\n",
        "                valid_idx += 1\n",
        "            else:\n",
        "                full_probs[i] = np.array([0.5, 0.5])\n",
        "        return full_probs\n",
        "\n",
        "# === LIME explainer with whitespace as k-mer separator ===\n",
        "explainer = LimeTextExplainer(class_names=class_names, split_expression='\\\\s+')\n",
        "\n",
        "# === Select top-N high-confidence toxic sequences ===\n",
        "raw_sequences = df['sequence'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "kmer_texts = df['kmers'].tolist()\n",
        "\n",
        "probs = lime_predict_kmers(kmer_texts)\n",
        "high_conf_ids = np.where((np.array(labels) == 1) & (probs[:, 1] > 0.8))[0]\n",
        "selected_ids = high_conf_ids[:30]\n",
        "\n",
        "# === Run LIME explanation ===\n",
        "for i, idx in enumerate(selected_ids):\n",
        "    kmer_input = kmer_texts[idx]\n",
        "    original_seq = df.iloc[idx]['sequence']\n",
        "\n",
        "    explanation = explainer.explain_instance(kmer_input, lime_predict_kmers, num_features=10, labels=[1], num_samples=1000)\n",
        "\n",
        "    print(f\"\\n🧬 Sequence {i+1}: {original_seq}\")\n",
        "    print(\"Top influential k-mers (toward Allergen):\")\n",
        "    for token, weight in explanation.as_list(label=1):\n",
        "        print(f\"  {token}: {weight:.4f}\")\n",
        "\n",
        "    # Highlight influential regions in the original sequence\n",
        "    highlighted = original_seq\n",
        "    sorted_kmers = sorted(explanation.as_list(label=1), key=lambda x: abs(x[1]), reverse=True)\n",
        "    for kmer, _ in sorted_kmers:\n",
        "        highlighted = highlighted.replace(kmer, f\"<{kmer}>\")\n",
        "    print(\"Highlighted:\", highlighted)\n",
        "\n",
        "    try:\n",
        "        explanation.show_in_notebook()\n",
        "        fig = explanation.as_pyplot_figure(label=1)\n",
        "        plt.title(f\"LIME Explanation for Sequence {i+1}\")\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate plot for sequence {i+1}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KKI0QsD8UXvl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "a2549afd-194d-4276-8e0e-a62313a039b1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lime'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3050309917.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlime_text\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLimeTextExplainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lime'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# === Load dataset ===\n",
        "df = pd.read_csv(\"Allergen_combined.csv\")\n",
        "df['sequence'] = df['sequence'].astype(str)\n",
        "df['label'] = df['Allergen']\n",
        "\n",
        "# === Tokenization into k-mers ===\n",
        "def seq_to_kmers(seq, k=8):\n",
        "    return ' '.join([seq[i:i + k] for i in range(len(seq) - k + 1)])\n",
        "\n",
        "k = 8\n",
        "df['kmers'] = df['sequence'].apply(lambda seq: seq_to_kmers(seq, k))\n",
        "\n",
        "# === Helper to reconstruct full sequence from k-mers ===\n",
        "def kmers_to_seq(kmer_str, k=8):\n",
        "    kmers = kmer_str.split()\n",
        "    if not kmers:\n",
        "        return ''\n",
        "    return kmers[0] + ''.join([k[-1] for k in kmers[1:]])\n",
        "\n",
        "# === Prediction wrapper for LIME (accepts k-mer strings) ===\n",
        "class_names = ['Allergen', 'non-Allergen']\n",
        "\n",
        "def lime_predict_kmers(kmer_texts):\n",
        "    # Convert k-mer text back to raw sequences\n",
        "    sequences = [kmers_to_seq(text, k) for text in kmer_texts]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Filter out invalid inputs\n",
        "        valid_sequences = [seq for seq in sequences if isinstance(seq, str) and len(seq) > 0]\n",
        "        if not valid_sequences:\n",
        "            return np.array([[0.5, 0.5]] * len(sequences))\n",
        "\n",
        "        # ESM and one-hot encodings\n",
        "        esm_feats = extract_esm_embeddings(valid_sequences)  # tensor [B, D]\n",
        "        onehot_seqs = sequence_to_onehot(valid_sequences).float()  # tensor [B, L, 4]\n",
        "        outputs = model(esm_feats, onehot_seqs)\n",
        "        probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
        "\n",
        "        # Reassign to full array\n",
        "        full_probs = np.zeros((len(sequences), len(class_names)))\n",
        "        valid_idx = 0\n",
        "        for i, seq in enumerate(sequences):\n",
        "            if isinstance(seq, str) and len(seq) > 0:\n",
        "                full_probs[i] = probs[valid_idx]\n",
        "                valid_idx += 1\n",
        "            else:\n",
        "                full_probs[i] = np.array([0.5, 0.5])\n",
        "        return full_probs\n",
        "\n",
        "# === LIME explainer with whitespace as k-mer separator ===\n",
        "explainer = LimeTextExplainer(class_names=class_names, split_expression='\\\\s+')\n",
        "\n",
        "# === Select top-N high-confidence toxic sequences ===\n",
        "raw_sequences = df['sequence'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "kmer_texts = df['kmers'].tolist()\n",
        "\n",
        "probs = lime_predict_kmers(kmer_texts)\n",
        "high_conf_ids = np.where((np.array(labels) == 0) & (probs[:, 1] > 0.8))[0]\n",
        "selected_ids = high_conf_ids[:30]\n",
        "\n",
        "# === Run LIME explanation ===\n",
        "for i, idx in enumerate(selected_ids):\n",
        "    kmer_input = kmer_texts[idx]\n",
        "    original_seq = df.iloc[idx]['sequence']\n",
        "\n",
        "    explanation = explainer.explain_instance(kmer_input, lime_predict_kmers, num_features=10, labels=[0], num_samples=1000)\n",
        "\n",
        "    print(f\"\\n🧬 Sequence {i+1}: {original_seq}\")\n",
        "    print(\"Top influential k-mers (toward non-Allergen):\")\n",
        "    for token, weight in explanation.as_list(label=0):\n",
        "        print(f\"  {token}: {weight:.4f}\")\n",
        "\n",
        "    # Highlight influential regions in the original sequence\n",
        "    highlighted = original_seq\n",
        "    sorted_kmers = sorted(explanation.as_list(label=0), key=lambda x: abs(x[1]), reverse=True)\n",
        "    for kmer, _ in sorted_kmers:\n",
        "        highlighted = highlighted.replace(kmer, f\"<{kmer}>\")\n",
        "    print(\"Highlighted:\", highlighted)\n",
        "\n",
        "    try:\n",
        "        explanation.show_in_notebook()\n",
        "        fig = explanation.as_pyplot_figure(label=0)\n",
        "        plt.title(f\"LIME Explanation for Sequence {i+1}\")\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate plot for sequence {i+1}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R29EXsgiUXrZ",
        "outputId": "0f709ed6-e941-4a1b-d44b-9e88066384b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: anchor-exp in /home/molecular16/.local/lib/python3.11/site-packages (0.0.2.0)\n",
            "Requirement already satisfied: numpy in /home/molecular16/anaconda3/lib/python3.11/site-packages (from anchor-exp) (1.24.3)\n",
            "Requirement already satisfied: scipy in /home/molecular16/anaconda3/lib/python3.11/site-packages (from anchor-exp) (1.11.1)\n",
            "Requirement already satisfied: spacy in /home/molecular16/.local/lib/python3.11/site-packages (from anchor-exp) (3.8.7)\n",
            "Requirement already satisfied: lime in /home/molecular16/.local/lib/python3.11/site-packages (from anchor-exp) (0.2.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from anchor-exp) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22->anchor-exp) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22->anchor-exp) (2.2.0)\n",
            "Requirement already satisfied: matplotlib in /home/molecular16/anaconda3/lib/python3.11/site-packages (from lime->anchor-exp) (3.7.2)\n",
            "Requirement already satisfied: tqdm in /home/molecular16/anaconda3/lib/python3.11/site-packages (from lime->anchor-exp) (4.65.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from lime->anchor-exp) (0.20.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from spacy->anchor-exp) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from spacy->anchor-exp) (1.10.8)\n",
            "Requirement already satisfied: jinja2 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from spacy->anchor-exp) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /home/molecular16/anaconda3/lib/python3.11/site-packages (from spacy->anchor-exp) (68.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from spacy->anchor-exp) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/molecular16/.local/lib/python3.11/site-packages (from spacy->anchor-exp) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /home/molecular16/.local/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy->anchor-exp) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /home/molecular16/.local/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->anchor-exp) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->anchor-exp) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->anchor-exp) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->anchor-exp) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->anchor-exp) (2023.7.22)\n",
            "Requirement already satisfied: networkx>=2.8 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime->anchor-exp) (3.1)\n",
            "Requirement already satisfied: pillow>=9.0.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime->anchor-exp) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime->anchor-exp) (2.31.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime->anchor-exp) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime->anchor-exp) (1.4.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.12->lime->anchor-exp) (0.2)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /home/molecular16/.local/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy->anchor-exp) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/molecular16/.local/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy->anchor-exp) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy->anchor-exp) (8.0.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /home/molecular16/.local/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy->anchor-exp) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /home/molecular16/.local/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy->anchor-exp) (14.0.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/molecular16/.local/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy->anchor-exp) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy->anchor-exp) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from jinja2->spacy->anchor-exp) (2.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime->anchor-exp) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime->anchor-exp) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime->anchor-exp) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime->anchor-exp) (1.4.4)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime->anchor-exp) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from matplotlib->lime->anchor-exp) (2.8.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /home/molecular16/.local/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->anchor-exp) (1.2.1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: six>=1.5 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->lime->anchor-exp) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->anchor-exp) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->anchor-exp) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/molecular16/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->anchor-exp) (0.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install anchor-exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wRjqZR0PUXqh",
        "outputId": "7896c76c-a923-4dc4-b946-2d6446b9a56d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'anchor'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-739043196.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0manchor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manchor_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'anchor'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from anchor import anchor_text\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# === Load dataset ===\n",
        "df = pd.read_csv(\"Allergen_combined.csv\")\n",
        "df['sequence'] = df['sequence'].astype(str)\n",
        "df['label'] = df['Allergen']\n",
        "\n",
        "# Drop sequences with length smaller than 6 and create a new dataframe\n",
        "df = df[df['sequence'].str.len() >= 8].copy()\n",
        "\n",
        "# === Convert sequence to k-mers ===\n",
        "def seq_to_kmers(seq, k=8):\n",
        "    return ' '.join([seq[i:i + k] for i in range(len(seq) - k + 1)])\n",
        "\n",
        "# === Convert k-mers back to sequence ===\n",
        "def kmers_to_seq(kmer_str, k=8):\n",
        "    kmers = kmer_str.split()\n",
        "    if not kmers: return ''\n",
        "    return kmers[0] + ''.join([k[-1] for k in kmers[1:]])\n",
        "\n",
        "k = 8\n",
        "df['kmers'] = df['sequence'].apply(lambda seq: seq_to_kmers(seq, k))\n",
        "kmer_texts = df['kmers'].tolist()\n",
        "raw_sequences = df['sequence'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "\n",
        "# === Prediction using ESM + one-hot ===\n",
        "def predict_fn_esm(sequences):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_sequences = [s for s in sequences if isinstance(s, str) and len(s) > 0]\n",
        "        if not valid_sequences:\n",
        "            return np.array([[0.5, 0.5]] * len(sequences))\n",
        "\n",
        "        esm_feats = extract_esm_embeddings(valid_sequences)\n",
        "        onehot = sequence_to_onehot(valid_sequences).float()\n",
        "        outputs = model(esm_feats, onehot)\n",
        "        probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "\n",
        "        full_probs = np.zeros((len(sequences), 2))\n",
        "        valid_idx = 0\n",
        "        for i, seq in enumerate(sequences):\n",
        "            if isinstance(seq, str) and len(seq) > 0:\n",
        "                full_probs[i] = probs[valid_idx]\n",
        "                valid_idx += 1\n",
        "            else:\n",
        "                full_probs[i] = np.array([0.5, 0.5])\n",
        "        return full_probs\n",
        "\n",
        "# === Wrapper for AnchorText (returns class predictions) ===\n",
        "def predict_probs_kmers_anchor(kmer_seqs):\n",
        "    recovered_seqs = [kmers_to_seq(text, k=k) for text in kmer_seqs]\n",
        "    return predict_fn_esm(recovered_seqs)\n",
        "\n",
        "def predict_class_kmers_anchor(kmer_seqs):\n",
        "    probs = predict_probs_kmers_anchor(kmer_seqs)\n",
        "    return np.argmax(probs, axis=1)\n",
        "\n",
        "# === Dummy tokenizer for AnchorText ===\n",
        "class DummyToken:\n",
        "    def __init__(self, text, idx):\n",
        "        self.text = text\n",
        "        self.idx = idx\n",
        "\n",
        "class DummyTokenizer:\n",
        "    def __call__(self, text):\n",
        "        tokens = text.split()\n",
        "        return [DummyToken(token, i) for i, token in enumerate(tokens)]\n",
        "\n",
        "# === Find top high-confidence toxic predictions ===\n",
        "probs = predict_fn_esm(raw_sequences)\n",
        "high_conf_ids = np.where((np.array(labels) == 1) & (probs[:, 1] > 0.8))[0]\n",
        "selected_ids = high_conf_ids[:30]\n",
        "\n",
        "# === Create AnchorText explainer ===\n",
        "class_names = ['non-Allergen', 'Allergen']\n",
        "explainer = anchor_text.AnchorText(nlp=DummyTokenizer(), class_names=class_names)\n",
        "\n",
        "# === Explain selected instances ===\n",
        "for i, idx in enumerate(selected_ids):\n",
        "    print(f\"\\n🧬 Explaining Sequence {i+1} (Index {idx})\")\n",
        "    print(\"Original Sequence:\", raw_sequences[idx])\n",
        "\n",
        "    explanation = explainer.explain_instance(\n",
        "        kmer_texts[idx],\n",
        "        classifier_fn=predict_class_kmers_anchor,\n",
        "        threshold=0.95\n",
        "    )\n",
        "\n",
        "    print(\"\\n🔍 Anchor Explanation:\")\n",
        "    print('Anchor (if these k-mers present → Allergen):', ' AND '.join(explanation.names()))\n",
        "    print('Precision:', explanation.precision())\n",
        "    print('Coverage:', explanation.coverage())\n",
        "    explanation.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pRvIpjQUXY8",
        "outputId": "b9793c2d-291a-4fcd-adec-a01c1e7acb39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧬 Explaining Sequence 1 (Index 17916)\n",
            "Original Sequence: CKSGGAWCGFDPHGCCGNCGCLVGFCYGTGCPDSTEAK\n",
            "\n",
            "🔍 Anchor Explanation:\n",
            "Anchor (if these k-mers present → non-Allergen): GFCYGTGC AND GGAWCGFD AND CYGTGCPD AND SGGAWCGF AND GCLVGFCY AND NCGCLVGF AND DPHGCCGN AND CGNCGCLV AND FCYGTGCP AND GFDPHGCC AND TGCPDSTE\n",
            "Precision: 0.9651567944250871\n",
            "Coverage: 0.0\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 97\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision:\u001b[39m\u001b[38;5;124m'\u001b[39m, explanation\u001b[38;5;241m.\u001b[39mprecision())\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoverage:\u001b[39m\u001b[38;5;124m'\u001b[39m, explanation\u001b[38;5;241m.\u001b[39mcoverage())\n\u001b[0;32m---> 97\u001b[0m explanation\u001b[38;5;241m.\u001b[39mshow_in_notebook()\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/anchor/anchor_explanation.py:104\u001b[0m, in \u001b[0;36mAnchorExplanation.show_in_notebook\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_in_notebook\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n\u001b[0;32m--> 104\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_html(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m     display(HTML(out))\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/anchor/anchor_explanation.py:100\u001b[0m, in \u001b[0;36mAnchorExplanation.as_html\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_html\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_html_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexp_map, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/anchor/anchor_text.py:219\u001b[0m, in \u001b[0;36mAnchorText.as_html\u001b[0;34m(self, exp)\u001b[0m\n\u001b[1;32m    217\u001b[0m example_obj \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, examples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m--> 219\u001b[0m     example_obj\u001b[38;5;241m.\u001b[39mappend(process_examples(examples, i))\n\u001b[1;32m    221\u001b[0m explanation \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m'\u001b[39m: exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    222\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcertainties\u001b[39m\u001b[38;5;124m'\u001b[39m: exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m [exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_precision\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[1;32m    223\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports\u001b[39m\u001b[38;5;124m'\u001b[39m: exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoverage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    224\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m: exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_precision\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    225\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples\u001b[39m\u001b[38;5;124m'\u001b[39m: example_obj}\n\u001b[1;32m    226\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlp(exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstance\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/anchor/anchor_text.py:212\u001b[0m, in \u001b[0;36mAnchorText.as_html.<locals>.process_examples\u001b[0;34m(examples, idx)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m ex:\n\u001b[1;32m    211\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlp(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m--> 212\u001b[0m     raw_indexes \u001b[38;5;241m=\u001b[39m [(processed[i]\u001b[38;5;241m.\u001b[39mtext, processed[i]\u001b[38;5;241m.\u001b[39midx, exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs]\n\u001b[1;32m    213\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrawIndexes\u001b[39m\u001b[38;5;124m'\u001b[39m: raw_indexes})\n\u001b[1;32m    214\u001b[0m out_dict[new] \u001b[38;5;241m=\u001b[39m out\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/anchor/anchor_text.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m ex:\n\u001b[1;32m    211\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlp(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m--> 212\u001b[0m     raw_indexes \u001b[38;5;241m=\u001b[39m [(processed[i]\u001b[38;5;241m.\u001b[39mtext, processed[i]\u001b[38;5;241m.\u001b[39midx, exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs]\n\u001b[1;32m    213\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrawIndexes\u001b[39m\u001b[38;5;124m'\u001b[39m: raw_indexes})\n\u001b[1;32m    214\u001b[0m out_dict[new] \u001b[38;5;241m=\u001b[39m out\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "from anchor import anchor_text\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# === Load dataset ===\n",
        "df = pd.read_csv(\"Allergen_combined.csv\")\n",
        "df['sequence'] = df['sequence'].astype(str)\n",
        "df['label'] = df['Allergen']\n",
        "\n",
        "# Drop sequences with length smaller than 6 and create a new dataframe\n",
        "df = df[df['sequence'].str.len() >= 8].copy()\n",
        "\n",
        "# === Convert sequence to k-mers ===\n",
        "def seq_to_kmers(seq, k=8):\n",
        "    return ' '.join([seq[i:i + k] for i in range(len(seq) - k + 1)])\n",
        "\n",
        "# === Convert k-mers back to sequence ===\n",
        "def kmers_to_seq(kmer_str, k=8):\n",
        "    kmers = kmer_str.split()\n",
        "    if not kmers: return ''\n",
        "    return kmers[0] + ''.join([k[-1] for k in kmers[1:]])\n",
        "\n",
        "k = 8\n",
        "df['kmers'] = df['sequence'].apply(lambda seq: seq_to_kmers(seq, k))\n",
        "kmer_texts = df['kmers'].tolist()\n",
        "raw_sequences = df['sequence'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "\n",
        "# === Prediction using ESM + one-hot ===\n",
        "def predict_fn_esm(sequences):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_sequences = [s for s in sequences if isinstance(s, str) and len(s) > 0]\n",
        "        if not valid_sequences:\n",
        "            return np.array([[0.5, 0.5]] * len(sequences))\n",
        "\n",
        "        esm_feats = extract_esm_embeddings(valid_sequences)\n",
        "        onehot = sequence_to_onehot(valid_sequences).float()\n",
        "        outputs = model(esm_feats, onehot)\n",
        "        probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "\n",
        "        full_probs = np.zeros((len(sequences), 2))\n",
        "        valid_idx = 0\n",
        "        for i, seq in enumerate(sequences):\n",
        "            if isinstance(seq, str) and len(seq) > 0:\n",
        "                full_probs[i] = probs[valid_idx]\n",
        "                valid_idx += 1\n",
        "            else:\n",
        "                full_probs[i] = np.array([0.5, 0.5])\n",
        "        return full_probs\n",
        "\n",
        "# === Wrapper for AnchorText (returns class predictions) ===\n",
        "def predict_probs_kmers_anchor(kmer_seqs):\n",
        "    recovered_seqs = [kmers_to_seq(text, k=k) for text in kmer_seqs]\n",
        "    return predict_fn_esm(recovered_seqs)\n",
        "\n",
        "def predict_class_kmers_anchor(kmer_seqs):\n",
        "    probs = predict_probs_kmers_anchor(kmer_seqs)\n",
        "    return np.argmax(probs, axis=1)\n",
        "\n",
        "# === Dummy tokenizer for AnchorText ===\n",
        "class DummyToken:\n",
        "    def __init__(self, text, idx):\n",
        "        self.text = text\n",
        "        self.idx = idx\n",
        "\n",
        "class DummyTokenizer:\n",
        "    def __call__(self, text):\n",
        "        tokens = text.split()\n",
        "        return [DummyToken(token, i) for i, token in enumerate(tokens)]\n",
        "\n",
        "# === Find top high-confidence toxic predictions ===\n",
        "probs = predict_fn_esm(raw_sequences)\n",
        "high_conf_ids = np.where((np.array(labels) == 0) & (probs[:, 1] > 0.8))[0]\n",
        "selected_ids = high_conf_ids[:30]\n",
        "\n",
        "# === Create AnchorText explainer ===\n",
        "class_names = ['non-Allergen', 'Allergen']\n",
        "explainer = anchor_text.AnchorText(nlp=DummyTokenizer(), class_names=class_names)\n",
        "\n",
        "# === Explain selected instances ===\n",
        "for i, idx in enumerate(selected_ids):\n",
        "    print(f\"\\n🧬 Explaining Sequence {i+1} (Index {idx})\")\n",
        "    print(\"Original Sequence:\", raw_sequences[idx])\n",
        "\n",
        "    explanation = explainer.explain_instance(\n",
        "        kmer_texts[idx],\n",
        "        classifier_fn=predict_class_kmers_anchor,\n",
        "        threshold=0.95\n",
        "    )\n",
        "\n",
        "    print(\"\\n🔍 Anchor Explanation:\")\n",
        "    print('Anchor (if these k-mers present → non-Allergen):', ' AND '.join(explanation.names()))\n",
        "    print('Precision:', explanation.precision())\n",
        "    print('Coverage:', explanation.coverage())\n",
        "    explanation.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wjSDTJ-eGmk"
      },
      "outputs": [],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ubxQjhiCeGmk",
        "outputId": "c2411db4-5336-49e1-a1a3-132ae6491ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shap_values' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-969958063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# === After computing shap_values ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Focus on class 1 (Allergen) and one-hot contributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0monehot_shap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# shape [L, 4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Aggregate residue-level contributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shap_values' is not defined"
          ]
        }
      ],
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "# === After computing shap_values ===\n",
        "# Focus on class 1 (Allergen) and one-hot contributions\n",
        "onehot_shap = shap_values[1][0]  # shape [L, 4]\n",
        "\n",
        "# Aggregate residue-level contributions\n",
        "token_scores = onehot_shap.max(axis=1)  # or mean(axis=1) depending on preference\n",
        "kmer_tokens = seq_to_kmers(original_seq, k).split()\n",
        "\n",
        "# Aggregate into k-mer scores\n",
        "kmer_scores = []\n",
        "for j in range(len(kmer_tokens)):\n",
        "    start = j\n",
        "    end = j + k\n",
        "    kmer_score = np.mean(token_scores[start:end])\n",
        "    kmer_scores.append(kmer_score)\n",
        "\n",
        "# === Create SHAP Explanation object ===\n",
        "shap_exp = shap.Explanation(\n",
        "    values=np.array(kmer_scores),\n",
        "    data=np.array(kmer_tokens),\n",
        "    feature_names=kmer_tokens,\n",
        "    base_values=explainer.expected_value[1] if hasattr(explainer, 'expected_value') else 0\n",
        ")\n",
        "\n",
        "# === Text visualization ===\n",
        "shap.plots.text(shap_exp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kW3i-s9OeGml",
        "outputId": "244f1871-9ab7-40b6-f63d-111ace1de4c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Allergen_combined.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4207667463.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# === Load dataset ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Allergen_combined.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Allergen'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Allergen_combined.csv'"
          ]
        }
      ],
      "source": [
        "import shap\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# === Load dataset ===\n",
        "df = pd.read_csv(\"Allergen_combined.csv\")\n",
        "df['sequence'] = df['sequence'].astype(str)\n",
        "df['label'] = df['Allergen']\n",
        "\n",
        "# Drop sequences with length smaller than 6 and create a new dataframe\n",
        "df = df[df['sequence'].str.len() >= 8].copy()\n",
        "\n",
        "# === Tokenization into k-mers ===\n",
        "def seq_to_kmers(seq, k=8):\n",
        "    return ' '.join([seq[i:i + k] for i in range(len(seq) - k + 1)])\n",
        "\n",
        "k = 8\n",
        "df['kmers'] = df['sequence'].apply(lambda seq: seq_to_kmers(seq, k))\n",
        "\n",
        "# === Helper to reconstruct full sequence from k-mers ===\n",
        "def kmers_to_seq(kmer_str, k=8):\n",
        "    kmers = kmer_str.split()\n",
        "    if not kmers:\n",
        "        return ''\n",
        "    return kmers[0] + ''.join([k[-1] for k in kmers[1:]])\n",
        "\n",
        "# === Prediction wrapper for SHAP ===\n",
        "class_names = ['non-Allergen', 'Allergen']\n",
        "\n",
        "def shap_predict_sequences(sequences):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        esm_feats = extract_esm_embeddings(sequences)  # tensor [B, D]\n",
        "        onehot_seqs = sequence_to_onehot(sequences).float()  # tensor [B, L, 4]\n",
        "        outputs = model(esm_feats, onehot_seqs)\n",
        "        probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
        "    return probs\n",
        "\n",
        "# === Select top-N high-confidence toxic sequences ===\n",
        "raw_sequences = df['sequence'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "\n",
        "probs = shap_predict_sequences(raw_sequences)\n",
        "high_conf_ids = np.where((np.array(labels) == 1) & (probs[:, 1] > 0.8))[0]\n",
        "selected_ids = high_conf_ids[:30]\n",
        "\n",
        "# === Build SHAP DeepExplainer ===\n",
        "background_sequences = raw_sequences[:50]  # background sample\n",
        "background_esm = extract_esm_embeddings(background_sequences)\n",
        "background_onehot = sequence_to_onehot(background_sequences).float()\n",
        "\n",
        "# Wrap model forward pass for SHAP\n",
        "class WrapperModel(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "    def forward(self, esm_feats, onehot_seqs):\n",
        "        return self.model(esm_feats, onehot_seqs)\n",
        "\n",
        "wrapped_model = WrapperModel(model)\n",
        "explainer = shap.DeepExplainer(wrapped_model, [background_esm, background_onehot])\n",
        "\n",
        "# === Run SHAP explanations with k-mer mapping and text visualization ===\n",
        "for i, idx in enumerate(selected_ids):\n",
        "    original_seq = raw_sequences[idx]\n",
        "    kmer_tokens = seq_to_kmers(original_seq, k).split()\n",
        "\n",
        "    esm_feats = extract_esm_embeddings([original_seq])\n",
        "    onehot_seq = sequence_to_onehot([original_seq]).float()\n",
        "\n",
        "    shap_values = explainer.shap_values([esm_feats, onehot_seq], check_additivity=False)\n",
        "\n",
        "    # Focus on one-hot contribution (shap_values[1])\n",
        "    onehot_shap = shap_values[1][0]  # [L, 4]\n",
        "    token_scores = onehot_shap.max(axis=1)  # contribution per residue\n",
        "\n",
        "    # Map scores back to k-mers\n",
        "    kmer_scores = []\n",
        "    for j in range(len(kmer_tokens)):\n",
        "        start = j\n",
        "        end = j + k\n",
        "        kmer_score = np.mean(token_scores[start:end])\n",
        "        kmer_scores.append(kmer_score)\n",
        "\n",
        "    # Sort influential k-mers\n",
        "    top_indices = np.argsort(-np.abs(kmer_scores))[:10]\n",
        "    print(f\"\\n🧬 Sequence {i+1}: {original_seq}\")\n",
        "    print(\"Top influential k-mers (toward Allergen):\")\n",
        "    for j in top_indices:\n",
        "        print(f\"  {kmer_tokens[j]}: {kmer_scores[j]:.4f}\")\n",
        "\n",
        "    # Highlight in sequence\n",
        "    highlighted = original_seq\n",
        "    influential_kmers = [kmer_tokens[j] for j in top_indices]\n",
        "    for kmer_tok in influential_kmers:\n",
        "        highlighted = highlighted.replace(kmer_tok, f\"<{kmer_tok}>\")\n",
        "    print(\"Highlighted:\", highlighted)\n",
        "\n",
        "    # === Create SHAP Explanation object for text visualization ===\n",
        "    shap_exp = shap.Explanation(\n",
        "        values=np.array(kmer_scores),\n",
        "        data=np.array(kmer_tokens),\n",
        "        feature_names=kmer_tokens,\n",
        "        base_values=explainer.expected_value[1] if hasattr(explainer, 'expected_value') else 0\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        shap.plots.text(shap_exp)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate SHAP text plot for sequence {i+1}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eoormgfbeGml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "7cad699d-a09b-45a0-94b9-bbb28a32b595"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Allergen_combined.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3499978629.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# === Load dataset ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Allergen_combined.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Allergen'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Allergen_combined.csv'"
          ]
        }
      ],
      "source": [
        "import shap\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# === Load dataset ===\n",
        "df = pd.read_csv(\"Allergen_combined.csv\")\n",
        "df['sequence'] = df['sequence'].astype(str)\n",
        "df['label'] = df['Allergen']\n",
        "\n",
        "# Drop sequences with length smaller than 6 and create a new dataframe\n",
        "df = df[df['sequence'].str.len() >= 8].copy()\n",
        "\n",
        "# === Tokenization into k-mers ===\n",
        "def seq_to_kmers(seq, k=8):\n",
        "    return ' '.join([seq[i:i + k] for i in range(len(seq) - k + 1)])\n",
        "\n",
        "k = 8\n",
        "df['kmers'] = df['sequence'].apply(lambda seq: seq_to_kmers(seq, k))\n",
        "\n",
        "# === Helper to reconstruct full sequence from k-mers ===\n",
        "def kmers_to_seq(kmer_str, k=8):\n",
        "    kmers = kmer_str.split()\n",
        "    if not kmers:\n",
        "        return ''\n",
        "    return kmers[0] + ''.join([k[-1] for k in kmers[1:]])\n",
        "\n",
        "# === Prediction wrapper for SHAP ===\n",
        "class_names = ['non-Allergen', 'Allergen']\n",
        "\n",
        "def shap_predict_sequences(sequences):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        esm_feats = extract_esm_embeddings(sequences)  # tensor [B, D]\n",
        "        onehot_seqs = sequence_to_onehot(sequences).float()  # tensor [B, L, 4]\n",
        "        outputs = model(esm_feats, onehot_seqs)\n",
        "        probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
        "    return probs\n",
        "\n",
        "# === Select top-N high-confidence toxic sequences ===\n",
        "raw_sequences = df['sequence'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "\n",
        "probs = shap_predict_sequences(raw_sequences)\n",
        "high_conf_ids = np.where((np.array(labels) == 0) & (probs[:, 1] > 0.8))[0]\n",
        "selected_ids = high_conf_ids[:30]\n",
        "\n",
        "# === Build SHAP DeepExplainer ===\n",
        "background_sequences = raw_sequences[:50]  # background sample\n",
        "background_esm = extract_esm_embeddings(background_sequences)\n",
        "background_onehot = sequence_to_onehot(background_sequences).float()\n",
        "\n",
        "# Wrap model forward pass for SHAP\n",
        "class WrapperModel(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "    def forward(self, esm_feats, onehot_seqs):\n",
        "        return self.model(esm_feats, onehot_seqs)\n",
        "\n",
        "wrapped_model = WrapperModel(model)\n",
        "explainer = shap.DeepExplainer(wrapped_model, [background_esm, background_onehot])\n",
        "\n",
        "# === Run SHAP explanations with k-mer mapping and text visualization ===\n",
        "for i, idx in enumerate(selected_ids):\n",
        "    original_seq = raw_sequences[idx]\n",
        "    kmer_tokens = seq_to_kmers(original_seq, k).split()\n",
        "\n",
        "    esm_feats = extract_esm_embeddings([original_seq])\n",
        "    onehot_seq = sequence_to_onehot([original_seq]).float()\n",
        "\n",
        "    shap_values = explainer.shap_values([esm_feats, onehot_seq], check_additivity=False)\n",
        "\n",
        "    # Focus on one-hot contribution (shap_values[1])\n",
        "    onehot_shap = shap_values[1][0]  # [L, 4]\n",
        "    token_scores = onehot_shap.max(axis=1)  # contribution per residue\n",
        "\n",
        "    # Map scores back to k-mers\n",
        "    kmer_scores = []\n",
        "    for j in range(len(kmer_tokens)):\n",
        "        start = j\n",
        "        end = j + k\n",
        "        kmer_score = np.mean(token_scores[start:end])\n",
        "        kmer_scores.append(kmer_score)\n",
        "\n",
        "    # Sort influential k-mers\n",
        "    top_indices = np.argsort(-np.abs(kmer_scores))[:10]\n",
        "    print(f\"\\n🧬 Sequence {i+1}: {original_seq}\")\n",
        "    print(\"Top influential k-mers (toward non-Allergen):\")\n",
        "    for j in top_indices:\n",
        "        print(f\"  {kmer_tokens[j]}: {kmer_scores[j]:.4f}\")\n",
        "\n",
        "    # Highlight in sequence\n",
        "    highlighted = original_seq\n",
        "    influential_kmers = [kmer_tokens[j] for j in top_indices]\n",
        "    for kmer_tok in influential_kmers:\n",
        "        highlighted = highlighted.replace(kmer_tok, f\"<{kmer_tok}>\")\n",
        "    print(\"Highlighted:\", highlighted)\n",
        "\n",
        "    # === Create SHAP Explanation object for text visualization ===\n",
        "    shap_exp = shap.Explanation(\n",
        "        values=np.array(kmer_scores),\n",
        "        data=np.array(kmer_tokens),\n",
        "        feature_names=kmer_tokens,\n",
        "        base_values=explainer.expected_value[1] if hasattr(explainer, 'expected_value') else 0\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        shap.plots.text(shap_exp)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate SHAP text plot for sequence {i+1}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIpFkkNBeGml"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# === Load dataset ===\n",
        "df = pd.read_csv(\"Allergen_combined.csv\")\n",
        "df['sequence'] = df['sequence'].astype(str)\n",
        "df['label'] = df['Allergen']\n",
        "\n",
        "# Drop sequences with length smaller than 6 and create a new dataframe\n",
        "df = df[df['sequence'].str.len() >= 8].copy()\n",
        "\n",
        "# === Tokenization into k-mers ===\n",
        "def seq_to_kmers(seq, k=8):\n",
        "    return ' '.join([seq[i:i + k] for i in range(len(seq) - k + 1)])\n",
        "\n",
        "k = 8\n",
        "df['kmers'] = df['sequence'].apply(lambda seq: seq_to_kmers(seq, k))\n",
        "\n",
        "# === Helper to reconstruct full sequence from k-mers ===\n",
        "def kmers_to_seq(kmer_str, k=8):\n",
        "    kmers = kmer_str.split()\n",
        "    if not kmers:\n",
        "        return ''\n",
        "    return kmers[0] + ''.join([k[-1] for k in kmers[1:]])\n",
        "\n",
        "# === Prediction wrapper for SHAP ===\n",
        "class_names = ['non-Allergen', 'Allergen']\n",
        "\n",
        "def shap_predict_sequences(sequences):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        esm_feats = extract_esm_embeddings(sequences)  # tensor [B, D]\n",
        "        onehot_seqs = sequence_to_onehot(sequences).float()  # tensor [B, L, 4]\n",
        "        outputs = model(esm_feats, onehot_seqs)\n",
        "        probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
        "    return probs\n",
        "\n",
        "# === Select top-N high-confidence toxic sequences ===\n",
        "raw_sequences = df['sequence'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "\n",
        "probs = shap_predict_sequences(raw_sequences)\n",
        "high_conf_ids = np.where((np.array(labels) == 1) & (probs[:, 1] > 0.8))[0]\n",
        "selected_ids = high_conf_ids[:30]\n",
        "\n",
        "# === Build SHAP DeepExplainer ===\n",
        "background_sequences = raw_sequences[:50]  # background sample\n",
        "background_esm = extract_esm_embeddings(background_sequences)\n",
        "background_onehot = sequence_to_onehot(background_sequences).float()\n",
        "\n",
        "# Wrap model forward pass for SHAP\n",
        "class WrapperModel(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "    def forward(self, esm_feats, onehot_seqs):\n",
        "        return self.model(esm_feats, onehot_seqs)\n",
        "\n",
        "wrapped_model = WrapperModel(model)\n",
        "explainer = shap.DeepExplainer(wrapped_model, [background_esm, background_onehot])\n",
        "\n",
        "# === Run SHAP explanations with k-mer mapping, text + bar + heatmap visualization ===\n",
        "for i, idx in enumerate(selected_ids):\n",
        "    original_seq = raw_sequences[idx]\n",
        "    kmer_tokens = seq_to_kmers(original_seq, k).split()\n",
        "\n",
        "    esm_feats = extract_esm_embeddings([original_seq])\n",
        "    onehot_seq = sequence_to_onehot([original_seq]).float()\n",
        "\n",
        "    shap_values = explainer.shap_values([esm_feats, onehot_seq], check_additivity=False)\n",
        "\n",
        "    # onehot_shap has shape [B, L, C] (batch, length, channels)\n",
        "    onehot_shap = onehot_shap[0]   # now [L, C]\n",
        "\n",
        "    # Signed max-abs aggregation across channels\n",
        "    max_abs_idx = np.argmax(np.abs(onehot_shap), axis=1)          # [L]\n",
        "    seq_values = onehot_shap[np.arange(onehot_shap.shape[0]), max_abs_idx]  # [L]\n",
        "\n",
        "    # Map residue scores back to k-mers by averaging over the window\n",
        "    kmer_scores = []\n",
        "    for j in range(len(kmer_tokens)):\n",
        "        start = j\n",
        "        end = j + k\n",
        "        kmer_scores.append(np.mean(seq_values[start:end]))\n",
        "    kmer_scores = np.array(kmer_scores)\n",
        "\n",
        "    # Sort influential k-mers\n",
        "    top_indices = np.argsort(-np.abs(kmer_scores))[:10]\n",
        "    print(f\"\\n🧬 Sequence {i+1}: {original_seq}\")\n",
        "    print(\"Top influential k-mers (toward FRS):\")\n",
        "    for j in top_indices:\n",
        "        print(f\"  {kmer_tokens[j]}: {kmer_scores[j]:.4f}\")\n",
        "\n",
        "    # Highlight in sequence\n",
        "    highlighted = original_seq\n",
        "    influential_kmers = [kmer_tokens[j] for j in top_indices]\n",
        "    for kmer_tok in influential_kmers:\n",
        "        highlighted = highlighted.replace(kmer_tok, f\"<{kmer_tok}>\")\n",
        "    print(\"Highlighted:\", highlighted)\n",
        "\n",
        "    # === Create SHAP Explanation object ===\n",
        "    shap_exp = shap.Explanation(\n",
        "        values=kmer_scores,\n",
        "        data=np.array(kmer_tokens),\n",
        "        feature_names=kmer_tokens,\n",
        "        base_values=explainer.expected_value[1] if hasattr(explainer, 'expected_value') else 0\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Text visualization\n",
        "        shap.plots.text(shap_exp)\n",
        "\n",
        "        # Bar visualization\n",
        "        shap.plots.bar(shap_exp, max_display=10)\n",
        "\n",
        "        # --- Residue-level SHAP heatmap (matplotlib only) ---\n",
        "        vmax = max(1e-9, np.max(np.abs(seq_values)))\n",
        "        fig, ax = plt.subplots(figsize=(max(6, len(original_seq) * 0.18), 1.8))\n",
        "        im = ax.imshow(seq_values[np.newaxis, :], aspect='auto', cmap='coolwarm', vmin=-vmax, vmax=vmax)\n",
        "        ax.set_yticks([0])\n",
        "        ax.set_yticklabels(['SHAP'])\n",
        "        ax.set_xticks(range(len(original_seq)))\n",
        "        ax.set_xticklabels(list(original_seq), rotation=90, fontsize=8)\n",
        "        plt.title(f\"Residue-level SHAP Heatmap (Sequence {i+1})\")\n",
        "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate SHAP plot for sequence {i+1}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHzdllUseGmm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}